# NYC Crime Analytics - Proyecto de Machine Learning

Este proyecto implementa un pipeline completo de ciencia de datos para analizar y predecir la probabilidad de robos en la ciudad de Nueva York. Utiliza un modelo de Machine Learning entrenado con datos hist√≥ricos de denuncias y presenta los resultados a trav√©s de una aplicaci√≥n web interactiva construida con Flask.

El flujo de trabajo est√° orquestado con **Prefect** para garantizar la reproducibilidad y la automatizaci√≥n del preprocesamiento de datos y el entrenamiento del modelo.

---
## üöÄ Caracter√≠sticas Principales

* **Dashboard de Anal√≠tica**: Una p√°gina principal con m√©tricas clave del modelo y gr√°ficos visuales sobre la distribuci√≥n de cr√≠menes, los d√≠as m√°s peligrosos y los tipos de lugares con mayor incidencia.
* **Pron√≥stico Interactivo de Robos**: Una herramienta que permite al usuario configurar condiciones (distrito, d√≠a, hora, tipo de lugar) para obtener una predicci√≥n en tiempo real de la probabilidad de que un incidente sea un robo.
* **Mapa de Calor de Densidad**: Una visualizaci√≥n geoespacial que muestra las "zonas calientes" de denuncias de cr√≠menes en toda la ciudad, superpuesta con los l√≠mites de los distritos (Boroughs) para un mejor contexto.
* **Pipeline Automatizado con Prefect**: Todo el proceso de ETL (Extracci√≥n, Transformaci√≥n y Carga) y entrenamiento del modelo est√° encapsulado en un flujo de Prefect, lo que facilita su ejecuci√≥n y mantenimiento.

---
## üìÅ Estructura del Proyecto

El proyecto est√° organizado de la siguiente manera para separar la l√≥gica del pipeline, la aplicaci√≥n web y los datos:

```bash
/proyecto_crimen_nyc
|
|-- app/              # Contiene la aplicaci√≥n web Flask
|   |-- static/       # Archivos est√°ticos (im√°genes, GeoJSON)
|   |-- templates/    # Plantillas HTML de la aplicaci√≥n
|   |-- app.py        # L√≥gica principal del servidor web
|
|-- data/             # Almacena los datasets
|   |-- raw/          # Datos crudos descargados por el pipeline
|   |-- processed/    # Datos limpios y listos para el modelo
|
|-- models/           # Modelos de ML y preprocesadores entrenados
|
|-- src/              # Contiene el pipeline de datos con Prefect
|   |-- config.py
|   |-- data_ingestion.py
|   |-- preprocessing.py
|   |-- train.py
|   |-- evaluate.py
|   |-- pipeline.py
|
|-- requirements.txt  # Dependencias del proyecto
|-- run_app.py        # Script para iniciar la aplicaci√≥n web
|-- README.md         # Este archivo
```

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* Backend: Python, Flask
* Orquestaci√≥n de Datos: Prefect
* Machine Learning: Scikit-learn
* Manipulaci√≥n de Datos: Pandas
* Visualizaci√≥n: Matplotlib, Seaborn, Folium
* Entorno: Conda / venv

## ‚öôÔ∏è C√≥mo Correr el Proyecto
Sigue estos pasos para configurar y ejecutar el proyecto en tu m√°quina local.

1. Prerrequisitos
    - Tener Python 3.9 o superior instalado.
    - Se recomienda usar un entorno virtual (como venv o conda) para aislar las dependencias del proyecto.

2. Clonar el Repositorio
    - Abre una terminal y clona este repositorio (o simplemente descarga y descomprime el c√≥digo en una carpeta).

```Bash 
git clone <URL_DEL_REPOSITORIO>
cd proyecto_crimen_nyc
```

3. Configurar el Entorno Virtual
Crea y activa un entorno virtual.

```Bash

# Usando venv
python -m venv env
source env/bin/activate  # En Windows: env\Scripts\activate

# O usando conda
conda create -n ml-final python=3.9
conda activate ml-final
```

4. Instalar Dependencias
Instala todas las librer√≠as necesarias con el siguiente comando:

```Bash
pip install -r requirements.txt
```

5. Ejecutar el Pipeline de Datos (Paso Crucial)
Antes de poder usar la aplicaci√≥n web, debes ejecutar el pipeline de Prefect. Este paso se encarga de descargar los datos, limpiarlos y entrenar el modelo de Machine Learning.

Este comando solo necesita ser ejecutado una vez (o cada vez que quieras re-entrenar el modelo con datos nuevos).

```Bash
python -m src.pipeline
Espera a que la terminal muestre que todas las tareas se han completado. Esto crear√° los archivos necesarios en las carpetas data/processed y models.
```

6. Iniciar la Aplicaci√≥n Web
Una vez que el pipeline ha terminado, inicia el servidor de Flask:


```Bash
python run_app.py
La terminal te mostrar√° un mensaje indicando que el servidor est√° activo y escuchando en una direcci√≥n, usualmente http://127.0.0.1:5001.
```

7. Acceder a la Aplicaci√≥n
Abre tu navegador web y ve a la siguiente direcci√≥n:

http://127.0.0.1:5001

¬°Listo! Ahora puedes navegar por el dashboard, usar la herramienta de pron√≥stico y explorar el mapa de calor.